{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Household Power Consumption dataset is a multivariate time series dataset that describes\n",
    "the electricity consumption for a single household over four years. The data was collected\n",
    "between December 2006 and November 2010 and observations of power consumption within the\n",
    "household were collected every minute. It is a multivariate series comprised of seven variables\n",
    "(besides the date and time); they are:<br>\n",
    "* global active power: The total active power consumed by the household (kilowatts).\n",
    "* global reactive power: The total reactive power consumed by the household (kilowatts).\n",
    "* voltage: Average voltage (volts).\n",
    "* global intensity: Average current intensity (amps).\n",
    "* sub metering 1: Active energy for kitchen (watt-hours of active energy).\n",
    "* sub metering 2: Active energy for laundry (watt-hours of active energy).\n",
    "* sub metering 3: Active energy for climate control systems (watt-hours of active energy).\n",
    "\n",
    "Active and reactive energy refer to the technical details of alternative current. A fourth\n",
    "sub-metering variable can be created by subtracting the sum of three defined sub-metering\n",
    "variables from the total active energy. This dataset was introduced and analyzed in Chapter 16.\n",
    "Refer to that chapter for more details if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean-up the power usage dataset\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    " one_day = 60 * 24\n",
    " for row in range(values.shape[0]):\n",
    "  for col in range(values.shape[1]):\n",
    "   if isnan(values[row, col]):\n",
    "    values[row, col] = values[row - one_day, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "dataset = read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False,\n",
    "infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark all missing values\n",
    "dataset.replace('?', nan, inplace=True)\n",
    "# make dataset numeric\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing\n",
    "fill_missing(dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for for the remainder of sub metering\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] +\n",
    "values[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated dataset\n",
    "dataset.to_csv('household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive forecast strategies for the power usage dataset\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    " # split into standard weeks\n",
    " train, test = data[1:-328], data[-328:-6]\n",
    " # restructure into windows of weekly data\n",
    " train = array(split(train, len(train)/7))\n",
    " test = array(split(test, len(test)/7))\n",
    " return train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    " scores = list()\n",
    " # calculate an RMSE score for each day\n",
    " for i in range(actual.shape[1]):\n",
    " # calculate mse\n",
    " mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    " # calculate rmse\n",
    " rmse = sqrt(mse)\n",
    " # store\n",
    " scores.append(rmse)\n",
    " # calculate overall RMSE\n",
    " s = 0\n",
    " for row in range(actual.shape[0]):\n",
    "  for col in range(actual.shape[1]):\n",
    "   s += (actual[row, col] - predicted[row, col])**2\n",
    " score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    " return score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    " s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    " print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(model_func, train, test):\n",
    " # history is a list of weekly data\n",
    " history = [x for x in train]\n",
    " # walk-forward validation over each week\n",
    " predictions = list()\n",
    " for i in range(len(test)):\n",
    "  # predict the week\n",
    "  yhat_sequence = model_func(history)\n",
    "  # store the predictions\n",
    "  predictions.append(yhat_sequence)\n",
    "  # get real observation and add to history for predicting the next week\n",
    "  history.append(test[i, :])\n",
    " predictions = array(predictions)\n",
    " # evaluate predictions days for each week\n",
    " score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    " return score, scores\n",
    "\n",
    "# daily persistence model\n",
    "def daily_persistence(history):\n",
    "  # get the data for the prior week\n",
    " last_week = history[-1]\n",
    " # get the total active power for the last day\n",
    " value = last_week[-1, 0]\n",
    " # prepare 7 day forecast\n",
    " forecast = [value for _ in range(7)]\n",
    " return forecast\n",
    "\n",
    "# weekly persistence model\n",
    "def weekly_persistence(history):\n",
    " # get the data for the prior week\n",
    " last_week = history[-1]\n",
    " return last_week[:, 0]\n",
    "\n",
    "# week one year ago persistence model\n",
    "def week_one_year_ago_persistence(history):\n",
    " # get the data for the prior week\n",
    " last_week = history[-52]\n",
    " return last_week[:, 0]\n",
    "\n",
    "# load the new file\n",
    "dataset = read_csv('household_power_consumption_days.csv', header=0,\n",
    "infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# define the names and functions for the models we wish to evaluate\n",
    "models = dict()\n",
    "models['daily'] = daily_persistence\n",
    "models['weekly'] = weekly_persistence\n",
    "models['week-oya'] = week_one_year_ago_persistence\n",
    "# evaluate each model\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "for name, func in models.items():\n",
    " # evaluate and get scores\n",
    " score, scores = evaluate_model(func, train, test)\n",
    " # summarize scores\n",
    " summarize_scores(name, score, scores)\n",
    " # plot scores\n",
    " pyplot.plot(days, scores, marker='o', label=name)\n",
    "# show plot\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
